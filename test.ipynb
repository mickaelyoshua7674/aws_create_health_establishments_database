{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import csv\n",
    "import zipfile\n",
    "import traceback\n",
    "import sys\n",
    "import os\n",
    "import boto3\n",
    "import shutil\n",
    "\n",
    "BUCKET_NAME = \"files-cnes-datasus\"\n",
    "BASE_FILES_NAME = \"BASE_DE_DADOS_CNES\"\n",
    "FTP_FOLDER = \"cnes\"\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "#-----------------------------------------------------------------FUNCTIONS-----------------------------------------------------------------#\n",
    "def print_error() -> None:\n",
    "    \"\"\"Print the error message and exit script.\"\"\"\n",
    "    traceback.print_exc()\n",
    "    print(\"Closing...\")\n",
    "    sys.exit()\n",
    "\n",
    "def get_list_names_zipfiles_bucket(s3_client: boto3.client, bucket: str) -> list[str]:\n",
    "    \"\"\"Get list of all zipfiles in folder 'zipfiles/'\"\"\"\n",
    "    try:\n",
    "        print(\"Getting list of zipfiles in S3 Bucket...\")\n",
    "        response = s3_client.list_objects(Bucket=bucket, Prefix=\"zipfiles/\")[\"Contents\"]\n",
    "        content_zipfiles = [k[\"Key\"] for k in response]\n",
    "        if len(content_zipfiles) == 1:\n",
    "            print(\"No zip files in Bucket folder 'zipfiles/'.\\n\")\n",
    "            return []\n",
    "        else:\n",
    "            print(\"Names collected.\\n\")\n",
    "            return [item[len(\"zipfiles/\"):] for item in content_zipfiles][1:]\n",
    "    except:\n",
    "        print(\"Error getting names of zipfiles in Bucket.\")\n",
    "        print_error()\n",
    "\n",
    "def download_zipfile_bucket(s3_client: boto3.client, bucket: str, file: str) -> None:\n",
    "    \"\"\"Download zipfile from S3 Bucket in the same folder that the script is located.\"\"\"\n",
    "    print(f\"Downloading {file}...\")\n",
    "    s3_client.download_file(\n",
    "        Bucket=bucket,\n",
    "        Key=\"zipfiles/\" + file,\n",
    "        Filename=\"./\" + file\n",
    "    )\n",
    "    print(f\"{file} downloaded.\\n\")\n",
    "\n",
    "def unzip_and_organize(s3_client: boto3.client, bucket: str, zip: str, folder: str) -> None:\n",
    "    \"\"\"\"\"\"\n",
    "    print(f\"\\nUnziping {zip}...\")\n",
    "    with zipfile.ZipFile(zip, \"r\") as zf: # openning zipfile\n",
    "        print(f\"{zip} unziped.\\n\")\n",
    "        for f in zf.namelist():\n",
    "            print(f\"Writing {f}...\")\n",
    "            with zf.open(f, \"r\") as table: # opening target file\n",
    "                r = csv.reader(io.TextIOWrapper(table, \"utf-8\"), delimiter=\";\") # decoding and reading file\n",
    "                rows = [row for row in r]\n",
    "\n",
    "                buff = io.StringIO()\n",
    "                csv.writer(buff).writerows(rows)\n",
    "\n",
    "                s3_client.put_object(Bucket=bucket, Key=\"raw_tables/\" + folder + f, Body=buff.getvalue().encode(\"utf-8\", \"replace\"))\n",
    "                print(f\"{f} written.\")\n",
    "\n",
    "def get_list_names_raw_tables_bucket(s3_client: boto3.client, bucket: str, folder: str) -> list[str]:\n",
    "    \"\"\"Get list of all content in 'raw_tables/' plus the folder from the input\"\"\"\n",
    "    response = s3_client.list_objects(Bucket=bucket)[\"Contents\"]\n",
    "    return [k[\"Key\"] for k in response if k[\"Key\"].startswith(\"raw_tables/\" + folder)]\n",
    "\n",
    "def upload_tables(s3_resource: boto3.resource, bucket: str, z: str, folder) -> None:\n",
    "    print(f\"Extracting {z}...\")\n",
    "    with zipfile.ZipFile(z, \"r\") as zf: # openning zipfile\n",
    "        zf.extractall(folder)\n",
    "        print(f\"{z} extracted.\\n\")\n",
    "    os.remove(z)\n",
    "\n",
    "    print(f\"Uploading tables from {z}...\")\n",
    "    for table in os.listdir(folder):\n",
    "        s3_resource.meta.client.upload_file(\n",
    "            Filename=folder + table,\n",
    "            Bucket=bucket,\n",
    "            Key=\"raw_tables/\" + folder + table\n",
    "        )\n",
    "    print(\"Tables uploaded.\\n\")\n",
    "    shutil.rmtree(folder[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting list of zipfiles in S3 Bucket...\n",
      "Names collected.\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# GET ZIPFILES NAMES FROM 'zipfiles/'\n",
    "names_zipfiles_bucket = get_list_names_zipfiles_bucket(s3_client, BUCKET_NAME)\n",
    "# DOWNLOAD ZIPFILES, UNZIP AND WRTIE CSV INTO 'raw_tables/'\n",
    "for z in names_zipfiles_bucket:\n",
    "    year_month = z.split(\".\")[0][-6:]\n",
    "    folder = year_month[:4] + \"/\" + year_month[-2:] + \"/\"\n",
    "    if len(get_list_names_raw_tables_bucket(s3_client, BUCKET_NAME, folder)) == 0:\n",
    "        download_zipfile_bucket(s3_client, BUCKET_NAME, z)\n",
    "        os.makedirs(folder)\n",
    "        upload_tables(s3_resource, BUCKET_NAME, z, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_names_raw_tables_bucket(s3_client: boto3.client, bucket: str, folder: str) -> list[str]:\n",
    "    \"\"\"Get list of all content in 'raw_tables/' plus the folder from the input\"\"\"\n",
    "    try:\n",
    "        response = s3_client.list_objects(Bucket=bucket, Prefix=\"raw_tables/\"+folder)[\"Contents\"]\n",
    "        return [k[\"Key\"] for k in response if k[\"Key\"]]\n",
    "    except KeyError: # if folder doesn't exist will be no 'Contents' key so is returned a KeyError\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = get_list_names_raw_tables_bucket(s3_client, BUCKET_NAME, \"2020/03/\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
